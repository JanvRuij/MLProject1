\section{Question 3}
After training and testing the neural network a training score of around 0.22 is found and a testing score of around 0.11. As for the MILP, when searching for the optimal solution, this is found relatively quickly and the predicted values equal the true values. But after testing the model either only 0's are returned, only ones, or random zeros and ones. I have tested a lot of different settings to try and reduce the overfitting, this would sometimes give very small improvements, but these seemed quite random. The improvements seemed random due to the fact that increasing my overfitting value lambda from 0.01 to 0.001001 would give a small improvement, but increasing it again by 0.000001 would have a negative effect. The overall advatage from the neural network over the MILP seems to be the fact that its easier to control for overfitting and underfitting while also producing good estimates. An MILP seems better in scenarios where (almost) identical data is inserted into the model each time, since the model can quickly find the optimal solution for one perticular set of input data.
